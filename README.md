# ğŸ“Š AplicaciÃ³n de AnÃ¡lisis de Datos - ETL y EDA

AplicaciÃ³n web interactiva desarrollada con Streamlit para el anÃ¡lisis exploratorio de datos (EDA) y procesos de extracciÃ³n, transformaciÃ³n y carga (ETL).

## ğŸš€ CaracterÃ­sticas

### MÃ³dulo 1: Ingesta y Procesamiento (ETL)
- **Carga dinÃ¡mica de datos**: Soporte para CSV, JSON y URLs
- **Limpieza interactiva**:
  - EliminaciÃ³n de duplicados
  - ImputaciÃ³n de valores nulos (Media, Mediana, Cero)
  - DetecciÃ³n y tratamiento de outliers usando mÃ©todo IQR
- **Feature Engineering**: CreaciÃ³n de nuevas columnas calculadas

### MÃ³dulo 2: VisualizaciÃ³n DinÃ¡mica (EDA)
- **Filtros globales**: Por fechas, categorÃ­as y valores numÃ©ricos
- **AnÃ¡lisis Univariado**: Histogramas, boxplots y estadÃ­sticas descriptivas
- **AnÃ¡lisis Bivariado**:
  - Matriz de correlaciÃ³n (Heatmap)
  - GrÃ¡ficos de dispersiÃ³n con lÃ­neas de tendencia
  - EvoluciÃ³n temporal (Line/Area Charts)
- **Reporte completo**: Resumen del dataset y descarga de datos procesados

## ğŸ“‹ Requisitos Previos

- Python 3.11 o superior
- pip (gestor de paquetes de Python)
- Git (opcional, para clonar el repositorio)

## ğŸ› ï¸ InstalaciÃ³n

### 1. Clonar el repositorio (opcional)

```bash
git clone <url-del-repositorio>
cd trabajo_final_ciencia_datos
```

O simplemente descarga los archivos del proyecto.



### 2. Instalar las dependencias

```bash
pip install -r requirements.txt
```

Esto instalarÃ¡ todas las librerÃ­as necesarias:
- streamlit (â‰¥1.31.0)
- pandas (â‰¥2.0.0)
- numpy (â‰¥1.24.0)
- matplotlib (â‰¥3.7.0)
- seaborn (â‰¥0.12.0)
- plotly (â‰¥5.18.0)

## ğŸ¯ Uso

### Ejecutar la aplicaciÃ³n localmente

```bash
streamlit run main_app.py
```

La aplicaciÃ³n se abrirÃ¡ automÃ¡ticamente en tu navegador en `http://localhost:8501`

### Si el navegador no se abre automÃ¡ticamente

Abre manualmente tu navegador y visita: `http://localhost:8501`

## ğŸ“– GuÃ­a de Uso

### Paso 1: Cargar Datos
1. Selecciona la fuente de datos (CSV, JSON o URL)
2. Sube tu archivo o ingresa la URL
3. El sistema mostrarÃ¡ informaciÃ³n sobre el tamaÃ±o y estructura del dataset

### Paso 2: Limpieza de Datos
1. **Eliminar duplicados**: Activa el checkbox si deseas remover registros duplicados
2. **Imputar valores nulos**: Selecciona el mÃ©todo de imputaciÃ³n (Media, Mediana o Cero)
3. **Tratar outliers**: Detecta y trata valores atÃ­picos usando el mÃ©todo IQR

### Paso 3: Feature Engineering
1. Crea nuevas columnas calculadas
2. Selecciona dos columnas numÃ©ricas y una operaciÃ³n (+, -, *, /)
3. Asigna un nombre a la nueva columna

### Paso 4: AnÃ¡lisis Exploratorio
1. **Aplica filtros globales** (opcional):
   - Rango de fechas
   - CategorÃ­as especÃ­ficas
   - Valores numÃ©ricos

2. **Explora las pestaÃ±as**:
   - **AnÃ¡lisis Univariado**: Distribuciones y estadÃ­sticas
   - **AnÃ¡lisis Bivariado**: Correlaciones y relaciones entre variables
   - **Reporte**: Vista completa y descarga de datos procesados

## ğŸ“ Estructura del Proyecto

```
trabajo_final_ciencia_datos/
â”‚
â”œâ”€â”€ main_app.py                          # AplicaciÃ³n principal de Streamlit
â”œâ”€â”€ requirements.txt                     # Dependencias del proyecto
â”œâ”€â”€ runtime.txt                          # VersiÃ³n de Python para deployment
â”œâ”€â”€ README.md                            # Este archivo
â”‚
â”œâ”€â”€ .streamlit/
â”‚   â””â”€â”€ config.toml                      # ConfiguraciÃ³n de Streamlit
â”‚
â””â”€â”€ verificar_dataset.ipynb              # Notebook de verificaciÃ³n del dataset
```


```
